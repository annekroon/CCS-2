@article{brosius_trust_2019,
	title = {Trust in the European Union: Effects of the information environment},
	volume = {34},
	issn = {0267-3231, 1460-3705},
	url = {http://journals.sagepub.com/doi/10.1177/0267323118810843},
	doi = {10.1177/0267323118810843},
	shorttitle = {Trust in the European Union},
	abstract = {Over the past decade, the European Union has lost the trust of many citizens. This article investigates whether and how media information, in particular visibility and tonality, impact trust in the European Union among citizens. Combining content analysis and Eurobarometer survey data from 10 countries between 2004 and 2015, we study both direct and moderating media effects. Media tone and visibility have limited direct effects on trust in the European Union, but they moderate the relation between trust in national institutions and trust in the European Union. This relation is amplified when the European Union is more visible in the media and when media tone is more positive towards the European Union, whereas it is dampened when media tone is more negative. The findings highlight the role of news media in the crisis of trust in the European Union.},
	pages = {57--73},
	number = {1},
	journaltitle = {European Journal of Communication},
	shortjournal = {European Journal of Communication},
	author = {Brosius, Anna and van Elsas, Erika J and de Vreese, Claes H},
	urldate = {2022-01-13},
	date = {2019-02},
	langid = {english},
	file = {Brosius et al. - 2019 - Trust in the European Union Effects of the inform.pdf:/Users/marthe/Zotero/storage/KYFUWPHY/Brosius et al. - 2019 - Trust in the European Union Effects of the inform.pdf:application/pdf},
}


@article{schneider_what_2020,
	title = {What Is Important When We Evaluate Movies? Insights from Computational Analysis of Online Reviews},
	volume = {8},
	issn = {2183-2439},
	url = {https://www.cogitatiopress.com/mediaandcommunication/article/view/3134},
	doi = {10.17645/mac.v8i3.3134},
	shorttitle = {What Is Important When We Evaluate Movies?},
	abstract = {The question of what is important when we evaluate movies is crucial for understanding how lay audiences experience and evaluate entertainment products such as films. In line with this, subjective movie evaluation criteria ({SMEC}) have been conceptualized as mental representations of important attitudes toward specific film features. Based on exploratory and confirmatory factor analyses of self-report data from online surveys, previous research has found and validated eight dimensions. Given the large-scale evaluative information that is available in online users’ comments in movie databases, it seems likely that what online users write about movies may enrich our knowledge about {SMEC}. As a first fully exploratory attempt, drawing on an open-source dataset including movie reviews from {IMDb}, we estimated a correlated topic model to explore the underlying topics of those reviews. In 35,136 online movie reviews, the most prevalent topics tapped into three major categories—Hedonism, Actors’ Performance, and Narrative—and indicated what reviewers mostly wrote about. Although a qualitative analysis of the reviews revealed that users mention certain {SMEC}, results of the topic model covered only two {SMEC}: Story Innovation and Light-heartedness. Implications for {SMEC} and entertainment research are discussed.},
	pages = {153--163},
	number = {3},
	journaltitle = {Media and Communication},
	shortjournal = {{MaC}},
	author = {Schneider, Frank M. and Domahidi, Emese and Dietrich, Felix},
	urldate = {2022-01-13},
	date = {2020-08-13},
	langid = {english},
	file = {Schneider et al. - 2020 - What Is Important When We Evaluate Movies Insight.pdf:/Users/marthe/Zotero/storage/53DJ5TM9/Schneider et al. - 2020 - What Is Important When We Evaluate Movies Insight.pdf:application/pdf},
}

@thesis{poma-murialdo_gender_2019,
	title = {Gender Inequality in the Movie Industry:},
	abstract = {The current study aimed to evaluate gender inequality in the movie industry. The gender of the cast and top crew positions from all 4885 feature films that received a wide release in United States between 1982 and 2017 were evaluated. Data was collected by scraping online movie databases. In the first part of the study, three types of representation were considered. First, the analysis of the numerical representation confirmed that there is high gender inequality in both cast and crew. Second, the examination of the quality of these representations revealed that, while all genres are male dominated, comedy, drama, romance and music have a higher proportion of women that the other genres (female genres). An analysis using the Bechdel test, used as a measure of female independence, showed that most movies from female genres pass the test, while movies from other genres fail it. Third, the analysis of the centrality of the representations showed no significant difference between big and small studio size, as both were male dominated. The relationship between cast and crew indicated that a higher proportion of women in the crew increases the proportion of women in the cast, especially for female genres. Finally, the second part of the study evaluated the relationship between the cast and crew’s gender and movie success. Overall, more women in the cast is associated with lower online review scores, awards and tickets sold, while the effect for female crew is positive on online ratings.},
	pagetotal = {35},
	institution = {University of Amsterdam},
	type = {Master's Thesis},
	author = {Poma-Murialdo, Sebastián Cole},
	date = {2019},
	langid = {english},
	file = {Poma-Murialdo - Gender Inequality in the Movie Industry.pdf:/Users/marthe/Zotero/storage/VAYJSLFF/Poma-Murialdo - Gender Inequality in the Movie Industry.pdf:application/pdf},
}


@article{burggraaff_through_2020,
	title = {Through a different gate: An automated content analysis of how online news and print news differ},
	volume = {21},
	issn = {1464-8849, 1741-3001},
	url = {http://journals.sagepub.com/doi/10.1177/1464884917716699},
	doi = {10.1177/1464884917716699},
	shorttitle = {Through a different gate},
	abstract = {We investigate how news values differ between online and print news articles. We hypothesize that print and online articles differ in terms of news values because of differences in the routines used to produce them. Based on a quantitative automated content analysis of N = 762,095 Dutch news items, we show that online news items are more likely to be follow-up items than print items, and that there are further differences regarding news values like references to persons, the power elite, negativity, and positivity. In order to conduct this large-scale analysis, we developed innovative methods to automatically code a wide range of news values. In particular, this article demonstrates how techniques such as sentiment analysis, named entity recognition, supervised machine learning, and automated queries of external databases can be combined and used to study journalistic content. Possible explanations for the difference found between online and offline news are discussed.},
	pages = {112--129},
	number = {1},
	journaltitle = {Journalism},
	shortjournal = {Journalism},
	author = {Burggraaff, Christiaan and Trilling, Damian},
	urldate = {2022-01-13},
	date = {2020-01},
	langid = {english},
	file = {Burggraaff and Trilling - 2020 - Through a different gate An automated content ana.pdf:/Users/marthe/Zotero/storage/2XNX3YPI/Burggraaff and Trilling - 2020 - Through a different gate An automated content ana.pdf:application/pdf},
}

@article{kroon_guilty_2021,
	title = {Guilty by Association: Using Word Embeddings to Measure Ethnic Stereotypes in News Coverage},
	volume = {98},
	issn = {1077-6990, 2161-430X},
	url = {http://journals.sagepub.com/doi/10.1177/1077699020932304},
	doi = {10.1177/1077699020932304},
	shorttitle = {Guilty by Association},
	abstract = {The current study provides a new level of empirical evidence for the nature of ethnic stereotypes in news content by drawing on a sample of more than 3 million Dutch news items. The study’s findings demonstrate that universally accepted dimensions of stereotype content (i.e., low-status and high-threat attributes) can be replicated in news media content across a diverse set of ingroup and outgroup categories. Representations of minorities in newspapers have become progressively remote from factual integration outcomes, and are therefore rather an artifact of news production processes than a true reflection of what is actually happening in society.},
	pages = {451--477},
	number = {2},
	journaltitle = {Journalism \& Mass Communication Quarterly},
	shortjournal = {Journalism \& Mass Communication Quarterly},
	author = {Kroon, Anne C. and Trilling, Damian and Raats, Tamara},
	urldate = {2022-01-13},
	date = {2021-06},
	langid = {english},
	file = {Kroon et al. - 2021 - Guilty by Association Using Word Embeddings to Me.pdf:/Users/marthe/Zotero/storage/ZCDMH7WL/Kroon et al. - 2021 - Guilty by Association Using Word Embeddings to Me.pdf:application/pdf},
}


@article{sanders_different_2020,
	title = {Different platforms for different patients’ needs: Automatic content analysis of different online health information platforms},
	volume = {137},
	issn = {10715819},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581918303380},
	doi = {10.1016/j.ijhcs.2019.102386},
	shorttitle = {Different platforms for different patients’ needs},
	abstract = {Prior online health research has mainly focused on the predictors or outcomes of online health information, leaving online health information itself understudied. Therefore, online health information has remained an umbrella term encompassing different platforms (expert- vs. peer-generated). A hybrid method that combines qualitative and computational methods is used to identify different topics discussed on these different platforms, and an initial model of patients’ social support needs was developed and applied to data obtained from the hybrid method. Using topic modeling (Nposts = 52.990), topics on two expert- and two peer-generated platforms were identified. Differences between and within platforms were found. While peer-generated platforms mainly covered interaction on emotional support topics, expert-generated platforms covered informational topics. Within peer-generated platforms, patients used their experiences differently.},
	pages = {102386},
	journaltitle = {International Journal of Human-Computer Studies},
	shortjournal = {International Journal of Human-Computer Studies},
	author = {Sanders, Remco and Linn, Annemiek J. and Araujo, Theo B. and Vliegenthart, Rens and van Eenbergen, Mies C. and van Weert, Julia C.M.},
	urldate = {2022-01-13},
	date = {2020-05},
	langid = {english},
	file = {Sanders et al. - 2020 - Different platforms for different patients’ needs.pdf:/Users/marthe/Zotero/storage/4YKLTGAP/Sanders et al. - 2020 - Different platforms for different patients’ needs.pdf:application/pdf},
}

@article{ha_automatically_2021,
	abstract = {Visual social media have emerged as an essential brand communication channel for advertisers and brands. The active use of hashtags has enabled advertisers to identify customers interested in their brands and better understand their consumers. However, some users post brand-incongruent content---for example, posts composed of brand-irrelevant images with brand-relevant hashtags. Such visual information mismatch can be problematic because it hinders other consumers' information search processes and advertisers' insight generation from consumer-initiated social media data. This study aims to characterize visually mismatched content in brand-related posts on Instagram and builds a visual information mismatch detection model using computer vision. We propose a machine-learning model based on three cues: image, text, and metadata. Our analysis shows the effectiveness of deep learning and the importance of combining text and image features for mismatch detection. We discuss the advantages of machine-learning methods as a novel research tool for advertising research and conclude with implications of our findings.},
	author = {Ha, Yui and Park, Kunwoo and Kim, Su Jung and Joo, Jungseock and Cha, Meeyoung},
	date = {2021-01-01},
	date-added = {2021-12-23 10:25:39 +0100},
	date-modified = {2021-12-23 10:25:39 +0100},
	doi = {10.1080/00913367.2020.1843091},
	file = {Ha et al. - 2021 - Automatically Detecting Image--Text Mismatch on Ins.pdf:/Users/marthe/Zotero/storage/L3X8SXVX/Ha et al. - 2021 - Automatically Detecting Image--Text Mismatch on Ins.pdf:application/pdf},
	issn = {0091-3367, 1557-7805},
	journaltitle = {Journal of Advertising},
	langid = {english},
	number = {1},
	pages = {52--62},
	shortjournal = {Journal of Advertising},
	title = {Automatically Detecting Image--Text Mismatch on Instagram with Deep Learning},
	url = {https://www.tandfonline.com/doi/full/10.1080/00913367.2020.1843091},
	urldate = {2021-12-23},
	volume = {50},
	Bdsk-Url-1 = {https://www.tandfonline.com/doi/full/10.1080/00913367.2020.1843091},
	Bdsk-Url-2 = {https://doi.org/10.1080/00913367.2020.1843091}}

@book{van_atteveldt_computational_2022,
	author = {Van Atteveldt, Wouter and Trilling, Damian and Calderon, Carlos Arcila},
	year = {2022},
	date-added = {2021-12-23 10:25:39 +0100},
	date-modified = {2021-12-23 10:25:39 +0100},
	publisher = {Wiley-Blackwell},
	title = {Computational Analysis of Communication}}

@article{jordan_mitchell,
	author = {Jordan, M. I. and Mitchell, T. M.},
	date = {2015},
	year={2015},
	date-added = {2021-12-23 10:25:39 +0100},
	date-modified = {2021-12-23 10:25:39 +0100},
	doi = {10.1126/science.aaa8415},
	file = {Jordan and Mitchell - 2015 - Machine learning Trends, perspectives, and prospe.pdf:/Users/marthe/Zotero/storage/HZYKUYS2/Jordan and Mitchell - 2015 - Machine learning Trends, perspectives, and prospe.pdf:application/pdf},
	issn = {0036-8075, 1095-9203},
	journaltitle = {Science},
	langid = {english},
	number = {6245},
	pages = {255--260},
	shortjournal = {Science},
	shorttitle = {Machine learning},
	title = {Machine learning: Trends, perspectives, and prospects},
	url = {https://www.science.org/doi/10.1126/science.aaa8415},
	urldate = {2021-12-23},
	volume = {349},
	Bdsk-Url-1 = {https://www.science.org/doi/10.1126/science.aaa8415},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.aaa8415}}

@article{sermanet_overfeat_2014,
	abstract = {We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a {ConvNet}. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the {ImageNet} Large Scale Visual Recognition Challenge 2013 ({ILSVRC}2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called {OverFeat}.},
	author = {Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Michael and Fergus, Rob and {LeCun}, Yann},
	date = {2014-02-23},
	date-added = {2021-12-23 10:25:39 +0100},
	date-modified = {2021-12-23 10:25:39 +0100},
	eprint = {1312.6229},
	eprinttype = {arxiv},
	file = {Sermanet et al. - 2014 - OverFeat Integrated Recognition, Localization and.pdf:/Users/marthe/Zotero/storage/YESRUDD8/Sermanet et al. - 2014 - OverFeat Integrated Recognition, Localization and.pdf:application/pdf},
	journaltitle = {{arXiv}:1312.6229 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	langid = {english},
	shorttitle = {{OverFeat}},
	title = {{OverFeat}: Integrated Recognition, Localization and Detection using Convolutional Networks},
	url = {http://arxiv.org/abs/1312.6229},
	urldate = {2021-12-23},
	Bdsk-Url-1 = {http://arxiv.org/abs/1312.6229}}

@article{meppelink_reliable_2021,
	title = {Reliable or not? An automated classification of webpages about early childhood vaccination using supervised machine learning},
	volume = {104},
	issn = {07383991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0738399120306376},
	doi = {10.1016/j.pec.2020.11.013},
	shorttitle = {Reliable or not?},
	abstract = {Objective: To investigate the applicability of supervised machine learning ({SML}) to classify health-related webpages as ‘reliable’ or ‘unreliable’ in an automated way. Methods: We collected the textual content of 468 different Dutch webpages about early childhood vaccination. Webpages were manually coded as ‘reliable’ or ‘unreliable’ based on their alignment with evidence-based vaccination guidelines. Four {SML} models were trained on part of the data, whereas the remaining data was used for model testing. Results: All models appeared to be successful in the automated identiﬁcation of unreliable (F1 scores: 0.54–0.86) and reliable information (F1 scores: 0.82–0.91). Typical words for unreliable information are ‘dr’, ‘immune system’, and ‘vaccine damage’, whereas ‘measles’, ‘child’, and ‘immunization rate’, were frequent in reliable information. Our best performing model was also successful in terms of out-ofsample prediction, tested on a dataset about {HPV} vaccination. Conclusion: Automated classiﬁcation of online content in terms of reliability, using basic classiﬁers, performs well and is particularly useful to identify reliable information. Practice implications: The classiﬁers can be used as a starting point to develop more complex classiﬁers, but also warning tools which can help people evaluate the content they encounter online. © 2020 The Authors. Published by Elsevier B.V. This is an open access article under the {CC} {BY}-{NC}-{ND} license (http://creativecommons.org/licenses/by-nc-nd/4.0/).},
	pages = {1460--1466},
	number = {6},
	journaltitle = {Patient Education and Counseling},
	shortjournal = {Patient Education and Counseling},
	author = {Meppelink, Corine S. and Hendriks, Hanneke and Trilling, Damian and van Weert, Julia C.M. and Shao, Anqi and Smit, Eline S.},
	year= {2021},
	date = {2021-06},
	langid = {english},
	file = {Meppelink et al. - 2021 - Reliable or not An automated classification of we.pdf:/Users/marthe/Zotero/storage/JVIZ9YA9/Meppelink et al. - 2021 - Reliable or not An automated classification of we.pdf:application/pdf},
}

@article{zhang_whose_2019,
	abstract = {This study focuses on the outpouring of sympathy in response to mass shootings and the contestation over gun policy on Twitter from 2012 to 2014 and relates these discourses to features of mass shooting events. We use two approaches to Twitter text analysis---hashtag grouping and supervised machine learning ({ML})---to triangulate an understanding of intensity and duration of ``thoughts and prayers,'' gun control, and gun rights discourses. We conduct parallel time series analyses to predict their temporal patterns in response to features of mass shootings. Our analyses reveal that while the total number of victims and child deaths consistently predicted public grieving and calls for gun control, public shootings consistently predicted the defense of gun rights. Further, the race of victims and perpetrators affected the levels of public mourning and policy debates, with the loss of black lives and the violence inflicted by white shooters generating less sympathy and policy discourses.},
	author = {Zhang, Yini and Shah, Dhavan and Foley, Jordan and Abhishek, Aman and Lukito, Josephine and Suk, Jiyoun and Kim, Sang Jung and Sun, Zhongkai and Pevehouse, Jon and Garlough, Christine},
	date = {2019-07-01},
	date-added = {2021-12-23 10:25:39 +0100},
	date-modified = {2021-12-23 10:25:39 +0100},
	doi = {10.1093/jcmc/zmz009},
	file = {Zhang et al. - 2019 - Whose Lives Matter Mass Shootings and Social Medi.pdf:/Users/marthe/Zotero/storage/7H5ER9JS/Zhang et al. - 2019 - Whose Lives Matter Mass Shootings and Social Medi.pdf:application/pdf},
	issn = {1083-6101},
	journaltitle = {Journal of Computer-Mediated Communication},
	langid = {english},
	number = {4},
	pages = {182--202},
	shorttitle = {Whose Lives Matter?},
	title = {Whose Lives Matter? Mass Shootings and Social Media Discourses of Sympathy and Policy, 2012--2014},
	url = {https://academic.oup.com/jcmc/article/24/4/182/5489530},
	urldate = {2021-12-23},
	volume = {24},
	Bdsk-Url-1 = {https://academic.oup.com/jcmc/article/24/4/182/5489530},
	Bdsk-Url-2 = {https://doi.org/10.1093/jcmc/zmz009}}

@article{van_zoonen_social_2016,
	year = {2016},
	abstract = {Despite the online availability of data, analysis of this information in academic research is arduous. This article explores the application of supervised machine learning ({SML}) to overcome challenges associated with online data analysis. In {SML} classifiers are used to categorize and code binary data. Based on a case study of Dutch employees' work-related tweets, this paper compares the coding performance of three classifiers, Linear Support Vector Machine, Na{\"\i}ve Bayes, and logistic regression. The performance of these classifiers is assessed by examining accuracy, precision, recall, the area under the precision-recall curve, and Krippendorf's Alpha. These indices are obtained by comparing the coding decisions of the classifier to manual coding decisions. The findings indicate that the Linear Support Vector Machine and Na{\"\i}ve Bayes classifiers outperform the logistic regression classifier. This study also compared the performance of these classifiers based on stratified random samples and random samples of training data. The findings indicate that in smaller training sets stratified random training samples perform better than random training samples, in large training sets (n ¼ 4000) random samples yield better results. Finally, the Linear Support Vector Machine classifier was trained with 4000 tweets and subsequently used to categorize 578,581 tweets obtained from 430 employees.},
	author = {Van Zoonen, Ward and Van der Meer, Toni G.L.A.},
	date = {2016-10},
	date-added = {2021-12-23 09:58:31 +0100},
	date-modified = {2021-12-23 09:58:31 +0100},
	doi = {10.1016/j.chb.2016.05.028},
	file = {van Zoonen and van der Meer - 2016 - Social media research The application of supervis.pdf:/Users/marthe/Zotero/storage/4LIRMG4P/van Zoonen and van der Meer - 2016 - Social media research The application of supervis.pdf:application/pdf},
	issn = {07475632},
	journaltitle = {Computers in Human Behavior},
	langid = {english},
	pages = {132--141},
	shortjournal = {Computers in Human Behavior},
	shorttitle = {Social media research},
	title = {Social media research: The application of supervised machine learning in organizational communication research.},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0747563216303557},
	urldate = {2021-12-23},
	volume = {63},
	Bdsk-Url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0747563216303557},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.chb.2016.05.028}}

@article{Boumans2016,
	author = {Boumans, Jelle W. and Trilling, Damian},
	doi = {10.1080/21670811.2015.1096598},
	file = {:Users/damian/Dropbox/uva/literatuur-mendeley/Boumans, Trilling{\_}2016.pdf:pdf},
	issn = {2167-0811},
	journal = {Digital Journalism},
	number = {1},
	pages = {8--23},
	title = {Taking stock of the toolkit: An overview of relevant autmated content analysis approaches and techniques for digital journalism scholars},
	volume = {4},
	year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1080/21670811.2015.1096598}}

@article{boyd2012,
	abstract = { The era of Big Data has begun. Computer scientists, physicists, economists, mathematicians, political scientists, bio-informaticists, sociologists, and other scholars are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions. Diverse groups argue about the potential benefits and costs of analyzing genetic sequences, social media interactions, health records, phone logs, government records, and other digital traces left by people. Significant questions emerge. Will large-scale search data help us create better tools, services, and public goods? Or will it usher in a new wave of privacy incursions and invasive marketing? Will data analytics help us understand online communities and political movements? Or will it be used to track protesters and suppress speech? Will it transform how we study human communication and culture, or narrow the palette of research options and alter what `research' means? Given the rise of Big Data as a socio-technical phenomenon, we argue that it is necessary to critically interrogate its assumptions and biases. In this article, we offer six provocations to spark conversations about the issues of Big Data: a cultural, technological, and scholarly phenomenon that rests on the interplay of technology, analysis, and mythology that provokes extensive utopian and dystopian rhetoric. },
	author = {Danah Boyd and Kate Crawford},
	date-added = {2015-02-19 20:28:12 +0100},
	date-modified = {2015-03-10 14:47:27 +0000},
	doi = {10.1080/1369118X.2012.678878},
	journal = {Information, Communication \& Society},
	number = {5},
	pages = {662-679},
	title = {Critical questions for {Big Data}},
	volume = {15},
	year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1080/1369118X.2012.678878}}

@article{Lazer2009,
	abstract = {A field is emerging that leverages the capacity to collect and analyze data at a scale that may reveal patterns of individual and group behaviors.},
	author = {Lazer, David and Pentland, Alex and Adamic, Lada and Aral, Sinan and Barab{\'{a}}si, Albert-L{\'{a}}szl{\'{o}} and Brewer, Devon and Christakis, Nicholas and Contractor, Noshir and Fowler, James and Gutmann, Myron and Jebara, Tony and King, Gary and Macy, Michael and Roy, Deb and van Alstyne, Marshall},
	doi = {10.1126/science.1167742},
	file = {:Users/damian/Dropbox/uva/literatuur-mendeley/Lazer et al.{\_}2009.pdf:pdf},
	isbn = {1939-0068},
	issn = {19395108},
	journal = {Science},
	mendeley-groups = {papers/bigdatahoofdstuk},
	pages = {721--723},
	pmid = {19197046},
	title = {Computational social science},
	volume = {323},
	year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1126/science.1167742}}

@article{Hilbert2019,
	author = {Hilbert, Martin and Barnett, George and Blumenstock, Joshua and Contractor, Noshir and Diesner, Jana and Frey, Seth and Gonz{\'{a}}lez-Bail{\'{o}}n, Sandra and Lamberso, PJ and Pan, Jennifer and Peng, Tai-Quan and Shen, Cuihua and Smaldino, Paul E and {Van Atteveldt}, Wouter and Waldherr, Annie and Zhang, Jingwen and Zhu, Jonathan J H},
	journal = {International Journal of Communication},
	pages = {3912--3934},
	title = {{Computational Communication Science : A Methodological Catalyzer for a Maturing Discipline}},
	volume = {13},
	year = {2019}}

@book{VanAtteveldt2008,
	address = {Charleston, SC},
	author = {Van Atteveldt, Wouter},
	file = {:Users/dami/Library/Application Support/Mendeley Desktop/Downloaded/van Atteveldt - 2008 - Semantic Network Analysis Techniques for Extracting, Representing, and Querying Media Content.pdf:pdf},
	isbn = {1439211361},
	publisher = {BookSurge},
	title = {Semantic Network Analysis: {Techniques} for Extracting, Representing, and Querying Media Content},
	year = {2008}}

@article{VanAtteveldt2018a,
	abstract = {ABSTRACTThe recent increase in digitally available data, tools, and processing power is fostering the use of computational methods to the study of communication. This special issue discusses the validity of using big data in communication science and showcases a number of new methods and applications in the fields of text and network analysis. Computational methods have the potential to greatly enhance the scientific study of communication because they allow us to move towards collaborative large-N studies of actual behavior in its social context. This requires us to develop new skills and infrastructure and meet the challenges of open, valid, reliable, and ethical ``big data'' research. By bringing together a number of leading scholars in one issue, we contribute to the increasing development and adaptation of computational methods in communication science.},
	author = {van Atteveldt, Wouter and Peng, Tai Quan},
	doi = {10.1080/19312458.2018.1458084},
	journal = {Communication Methods and Measures},
	number = {2-3},
	pages = {81--92},
	publisher = {Routledge},
	title = {{When Communication Meets Computation: Opportunities, Challenges, and Pitfalls in Computational Communication Science}},
	volume = {12},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1080/19312458.2018.1458084}}

@article{Vis2013,
	author = {Vis, Farida},
	date-added = {2015-02-19 20:30:07 +0100},
	date-modified = {2015-02-19 23:09:31 +0100},
	doi = {10.5210/fm.v18i10.4878},
	file = {:Users/dami/Library/Application Support/Mendeley Desktop/Downloaded/Vis - 2013 - A critical reflection on Big Data Considering APIs, researchers and tools as data makers.pdf:pdf},
	issn = {13960466},
	journal = {First Monday},
	number = {10},
	pages = {1--16},
	title = {A critical reflection on {Big Data}: Considering {APIs}, researchers and tools as data makers},
	volume = {18},
	year = {2013},
	Bdsk-Url-1 = {http://journals.uic.edu/ojs/index.php/fm/article/view/4878},
	Bdsk-Url-2 = {http://dx.doi.org/10.5210/fm.v18i10.4878}}

@article{Thelwall2012,
	author = {Thelwall, Mike and Buckley, Kevan and Paltoglou, Georgios},
	date-added = {2015-03-16 13:31:47 +0000},
	date-modified = {2015-03-16 13:32:09 +0000},
	doi = {10.1002/asi.21662},
	issn = {1532-2890},
	journal = {Journal of the American Society for Information Science and Technology},
	number = {1},
	pages = {163--173},
	title = {Sentiment strength detection for the social web},
	volume = {63},
	year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/asi.21662}}

@misc{Pennebaker2007,
	address = {Austin; TX},
	author = {Pennebaker, J. W. and Booth, R. J. and Francis, M. E.},
	publisher = {LIWC.net},
	title = {{Linguistic Inquiry and Word Count: LIWC}},
	year = {2007}}

@inproceedings{Hutto2014,
	author = {Hutto, Clayton J and Gilbert, Eric},
	booktitle = {Eighth International AAAI Conference on Weblogs and Social Media},
	title = {Vader: A parsimonious rule-based model for sentiment analysis of social media text},
	year = {2014}}

@article{Boukes2020,
	author = {Boukes, Mark and van de Velde, Bob and Araujo, Theo and Vliegenthart, Rens},
	doi = {10.1080/19312458.2019.1671966},
	issn = {1931-2458},
	journal = {Communication Methods and Measures},
	number = {2},
	pages = {83--104},
	publisher = {Routledge},
	title = {{What's the Tone? Easy Doesn't Do It: Analyzing Performance and Agreement Between Off-the-Shelf Sentiment Analysis Tools}},
	volume = {14},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1080/19312458.2019.1671966}}

@article{VanAtteveldt2019,
	author = {{van Atteveldt}, Wouter and Strycharz, Joanna and Trilling, Damian and Welbers, Kasper},
	file = {:home/damian/SURFdrive/literatuur-mendeley/Van Atteveldt et al.{\_}2019(2).pdf:pdf},
	journal = {International Journal of Communication},
	pages = {3935--3954},
	title = {{Toward Open Computational Communication Science : A Practical Road Map for Reusable Data and Code University of Amsterdam , the Netherlands}},
	volume = {13},
	year = {2019}}

@article{Mahrt2013,
	author = {Mahrt, Merja and Scharkow, Michael},
	date-added = {2015-02-19 20:30:14 +0100},
	date-modified = {2015-02-19 23:07:45 +0100},
	doi = {10.1080/08838151.2012.761700},
	file = {:Users/dami/Library/Application Support/Mendeley Desktop/Downloaded/Mahrt, Scharkow - 2013 - The Value of Big Data in Digital Media Research.pdf:pdf},
	issn = {0883-8151},
	journal = {Journal of Broadcasting \& Electronic Media},
	number = {1},
	pages = {20--33},
	title = {The Value of {Big Data} in Digital Media Research},
	volume = {57},
	year = {2013},
	Bdsk-Url-1 = {http://www.tandfonline.com/doi/abs/10.1080/08838151.2012.761700},
	Bdsk-Url-2 = {http://dx.doi.org/10.1080/08838151.2012.761700}}

@article{VanAtteveldt2021,
	author = {{van Atteveldt}, Wouter and {van der Velden}, Mariken A.C.G. and Boukes, Mark},
	doi = {10.1080/19312458.2020.1869198},
	issn = {19312466},
	journal = {Communication Methods and Measures},
	number = {00},
	pages = {1--20},
	publisher = {Routledge},
	title = {{The Validity of Sentiment Analysis:Comparing Manual Annotation, Crowd-Coding, Dictionary Approaches, and Machine Learning Algorithms}},
	volume = {00},
	year = {2021},
	Bdsk-Url-1 = {https://doi.org/10.1080/19312458.2020.1869198}}

@article{Vermeer2019,
	author = {Vermeer, Susan and Araujo, Theo and Bernritter, Stefan F. and van Noort, Guda},
	doi = {10.1016/j.ijresmar.2019.01.010},
	issn = {01678116},
	journal = {International Journal of Research in Marketing},
	number = {3},
	pages = {492--508},
	publisher = {Elsevier B.V.},
	title = {{Seeing the wood for the trees: How machine learning can help firms in identifying relevant electronic word-of-mouth in social media}},
	volume = {36},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.ijresmar.2019.01.010}}

@article{Burscher2015,
	author = {Burscher, Bj{\"{o}}rn and Vliegenthart, Rens and {De Vreese}, C. H.},
	doi = {10.1177/0002716215569441},
	issn = {0002-7162},
	journal = {The ANNALS of the American Academy of Political and Social Science},
	number = {1},
	pages = {122--131},
	title = {{Using supervised machine learning to code policy issues: Can classifiers generalize across contexts?}},
	volume = {659},
	year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1177/0002716215569441}}

@article{Burscher2014,
	author = {Burscher, Bj{\"{o}}rn and Odijk, Daan and Vliegenthart, Rens and de Rijke, Maarten and de Vreese, Claes H.},
	doi = {10.1080/19312458.2014.937527},
	issn = {1931-2458},
	journal = {Communication Methods and Measures},
	number = {3},
	pages = {190--206},
	title = {Teaching the computer to code frames in news: {C}omparing two supervised machine learning approaches to frame analysis},
	volume = {8},
	year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1080/19312458.2014.937527}}

@article{Hopkins2010,
	author = {Hopkins, Daniel J. and King, Gary},
	journal = {American Journal of Political Science},
	number = {1},
	pages = {229--247},
	title = {{A method of automated nonparametric content analysis for social science}},
	volume = {54},
	year = {2010}}

@inproceedings{BERT,
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5{\%} (7.7{\%} point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	archiveprefix = {arXiv},
	arxivid = {1810.04805},
	author = {Devlin, Jacob and Chang, Ming Wei and Lee, Kenton and Toutanova, Kristina},
	booktitle = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
	eprint = {1810.04805},
	file = {:home/damian/SURFdrive/literatuur-mendeley/Devlin et al.{\_}2019.pdf:pdf},
	isbn = {9781950737130},
	number = {Mlm},
	pages = {4171--4186},
	title = {{BERT: Pre-training of deep bidirectional transformers for language understanding}},
	volume = {1},
	year = {2019}}


@article{Locherbach2018,
abstract = {We developed 3bij3, a framework that presents a news app to participants, with contents that are displayed based on different recommendation logics. It tracks usage over time and enables large-scale field experiments.},
author = {Locherbach, Felicia and Trilling, Damian},
doi = {10.1109/eScience.2018.00093},
file = {:Users/anne/surfdrive/mendely-import/08588712.pdf:pdf},
isbn = {9781538691564},
journal = {Proceedings - IEEE 14th International Conference on eScience, e-Science 2018},
keywords = {Communication science,News exposure,Recommender systems,Web application},
pages = {350--351},
title = {{3bij3: A framework for testing effects of recommender systems on news exposure}},
year = {2018}
}



@article{Kim2019,
abstract = {Abstract Recommendation algorithms are widely used in online cultural markets to provide personalized suggestions for products like books and movies. At the heart of the commercial success of recommendation algorithms is their ability to make an accurate prediction of a target person's preferences for previously unseen items. Can these algorithms also be used to predict which health messages an individual will evaluate favorably, and thereby provide effective tailored communication to the person? Although there is evidence that message tailoring enhances persuasion, little research has examined the effectiveness of recommendation algorithms for tailored health interventions aimed at promoting behavior change. We developed a message tailoring algorithm to select smoking-related public service announcements (PSAs) for smokers, and experimentally test its effectiveness in predicting a target smoker's evaluations of PSAs and encouraging smoking cessation. The tailoring algorithm was constructed using multiple levels of data on smokers' PSA rating history, individual differences, content features of the PSAs, and other smokers' PSA ratings. We conducted a longitudinal online experiment to examine its efficacy in comparison to two non-tailored methods: “best in show” (choosing messages most preferred by other smokers) and “off the shelf” (random selection from eligible ads). The results showed that the tailoring algorithm produced more accurate predictions of smokers' message evaluations than the simple-average method used for the “best in show” approach. Smokers who viewed PSAs recommended by the tailoring algorithm were more likely than those receiving a random set to evaluate the PSAs favorably and quit smoking. There was no significant difference between the “best in show” and “off the shelf” methods in message assessment and quitting behavior.},
author = {Kim, Hyun Suk and Yang, Sijia and Kim, Minji and Hemenway, Brett and Ungar, Lyle and Cappella, Joseph N.},
doi = {10.5117/ccr2019.1.005.sukk},
file = {:Users/anne/Downloads/document (2).pdf:pdf},
issn = {2665-9085},
journal = {Computational Communication Research},
number = {1},
pages = {103--129},
title = {{An experimental study of recommendation algorithms for tailored health communication}},
volume = {1},
year = {2019}
}


@article{boumans_taking_2016,
	title = {Taking Stock of the Toolkit: An overview of relevant automated content analysis approaches and techniques for digital journalism scholars},
	volume = {4},
	issn = {2167-0811, 2167-082X},
	url = {http://www.tandfonline.com/doi/full/10.1080/21670811.2015.1096598},
	doi = {10.1080/21670811.2015.1096598},
	shorttitle = {Taking Stock of the Toolkit},
	pages = {8--23},
	number = {1},
	journaltitle = {Digital Journalism},
	shortjournal = {Digital Journalism},
	author = {Boumans, Jelle W. and Trilling, Damian},
	urldate = {2022-02-28},
	date = {2016-01-02},
	langid = {english},
	file = {Boumans and Trilling - 2016 - Taking Stock of the Toolkit An overview of releva.pdf:/Users/marthe/Zotero/storage/P8SXLEZY/Boumans and Trilling - 2016 - Taking Stock of the Toolkit An overview of releva.pdf:application/pdf},
}


@article{Brinberg2021,
abstract = {The digital text traces left by computer-mediated communication (CMC) provide a new opportunity to test theories of relational processes that were originally developed through observation of face-to-face interactions. Communication accommodation theory, for example, suggests that conversation partners' verbal (and non-verbal) behaviors become more similar as relationships develop. Using a corpus of 1+ million text messages that 41 college-age romantic couples sent to each other during their first year of dating, this study examines how linguistic alignment of new romantic couples' CMC changes during relationship formation. Results from nonlinear growth models indicate that three aspects of daily linguistic alignment (syntactic—language style matching, semantic—latent semantic analysis, overall—cosine similarity) all exhibit exponential growth to an asymptote as romantic relationships form. Beyond providing empirical support that communication accommodation theory also applies in romantic partners' CMC, this study demonstrates how relational processes can be examined using digital trace data.},
author = {Brinberg, Miriam and Ram, Nilam},
doi = {10.1093/joc/jqab012},
file = {:Users/anne/Downloads/jqab012.pdf:pdf},
issn = {0021-9916},
journal = {Journal of Communication},
keywords = {communication,computer-mediated,intensive longitudinal analysis,linguistic alignment,relationship development,romantic relationships},
number = {3},
pages = {454--477},
title = {{Do new romantic couples use more similar language over time? Evidence from intensive longitudinal text messages}},
volume = {71},
year = {2021}
}




@article{Wieland2021,
abstract = {Journalistic media increasingly address changing user behaviour online by implementing algorithmic recommendations on their pages. While social media extensively rely on user data for personalized recommendations, journalistic media may choose to aim to improve the user experience based on textual features such as thematic similarity. From a societal viewpoint, these recommendations should be as diverse as possible. Users, however, tend to prefer recommendations that enable “serendipity”-the perception of an item as a welcome surprise that strikes just the right balance between more similarly useful but still novel content. By conducting a representative online survey with n = 588 respondents, we investigate how users evaluate algorithmic news recommendations (recommendation satisfaction, as well as perceived novelty and unexpectedness) based on different similarity settings and how individual dispositions (news interest, civic information norm, need for cognitive closure, etc.) may affect these evaluations. The core piece of our survey is a self-programmed recommendation system that accesses a database of vectorized news articles. Respondents search for a personally relevant keyword and select a suitable article, after which another article is recommended automatically, at random, using one of three similarity settings. Our findings show that users prefer recommendations of the most similar articles, which are at the same time perceived as novel, but not necessarily unexpected. However, user evaluations will differ depending on personal characteristics such as formal education, the civic information norm, and the need for cognitive closure.},
author = {Wieland, Mareike and {Von Nordheim}, Gerret and {Kleinen-Von K{\"{o}}nigsl{\"{o}}w}, Katharina},
doi = {10.17645/mac.v9i4.4241},
file = {:Users/anne/surfdrive/mendely-import/MaC 9(4) - One Recommender Fits All_ An Exploration of User Satisfaction With Text-Based News Recommender Systems.pdf:pdf},
issn = {21832439},
journal = {Media and Communication},
keywords = {Algorithm-based recommenders,Diversity,News recommender design,Recommender field experiment,Reliable surprise},
number = {4},
pages = {208--221},
title = {{One recommender fits all? An exploration of user satisfaction with text-based news recommender systems}},
volume = {9},
year = {2021}
}




@article{Moller2018,
abstract = {In the debate about filter bubbles caused by algorithmic news recommendation, the conceptualization of the two core concepts in this debate, diversity and algorithms, has received little attention in social scientific research. This paper examines the effect of multiple recommender systems on different diversity dimensions. To this end, it maps different values that diversity can serve, and a respective set of criteria that characterizes a diverse information offer in this particular conception of diversity. We make use of a data set of simulated article recommendations based on actual content of one of the major Dutch broadsheet newspapers and its users (N=21,973 articles, N=500 users). We find that all of the recommendation logics under study proved to lead to a rather diverse set of recommendations that are on par with human editors and that basing recommendations on user histories can substantially increase topic diversity within a recommendation set.},
author = {M{\"{o}}ller, Judith and Trilling, Damian and Helberger, Natali and van Es, Bram},
doi = {10.1080/1369118X.2018.1444076},
file = {:Users/anne/surfdrive/uva/teaching/CCS-2-materials/literatuur/recsys/Do not blame it on the algorithm an empirical assessment of multiple recommender systems and their impact on content diversity.pdf:pdf},
issn = {14684462},
journal = {Information Communication and Society},
keywords = {News,automated content classification,diversity metrics,filter bubbles,recommender systems},
number = {7},
pages = {959--977},
publisher = {Taylor & Francis},
title = {{Do not blame it on the algorithm: an empirical assessment of multiple recommender systems and their impact on content diversity}},
url = {https://doi.org/10.1080/1369118X.2018.1444076},
volume = {21},
year = {2018}
}

@article{Loecherbach2020,
abstract = {Today's online news environment is increasingly characterized by personalized news selections, relying on algorithmic solutions for extracting relevant articles and composing an individual's news diet. Yet, the impact of such recommendation algorithms on how we consume and perceive news is still understudied. We therefore developed one of the first software solutions to conduct studies on effects of news recommender systems in a realistic setting. The web app of our framework (called 3bij3) displays real-time news articles selected by different mechanisms. 3bij3 can be used to conduct large-scale field experiments, in which participants' use of the site can be tracked over extended periods of time. Compared to previous work, 3bij3 gives researchers control over the recommendation system under study and creates a realistic environment for the participants. It integrates web scraping, different methods to compare and classify news articles, different recommender systems, a web interface for participants, gamification elements, and a user survey to enrich the behavioural measures obtained.},
author = {Loecherbach, Felicia and Trilling, Damian},
doi = {10.5117/ccr2020.1.003.loec},
file = {:Users/anne/Downloads/03_CCR2020.1.003.LOEC.pdf:pdf},
issn = {2665-9085},
journal = {Computational Communication Research},
keywords = {computational social science,news,recommender systems,web},
number = {1},
pages = {53--79},
title = {{3bij3 – Developing a framework for researching recommender systems and their effects}},
volume = {2},
year = {2020}
}

@article{Hirschenberg2015,
author = {Hirschenberg, Julia and Manning, Christopher D},
file = {:Users/anne/surfdrive/mendely-import/Hirschenberg.pdf:pdf},
isbn = {9781405164535},
journal = {Science},
keywords = {Language comprehension,Language production},
number = {6245},
pages = {261--266},
title = {{Advances in natural langauge processing}},
url = {https://cs224d.stanford.edu/papers/advances.pdf},
volume = {349},
year = {2015}
}

@article{Sidorov2014,
abstract = {We show how to consider similarity between features for calculation of similarity of objects in the Vector Space Model (VSM) for machine learning algorithms and other classes of methods that involve similarity between objects. Unlike LSA, we assume that similarity between features is known (say, from a synonym dictionary) and does not need to be learned from the data. We call the proposed similarity measure soft similarity. Similarity between features is common, for example, in natural language processing: words, n-grams, or syntactic n-grams can be somewhat different (which makes them different features) but still have much in common: for example, words "play" and "game" are different but related. When there is no similarity between features then our soft similarity measure is equal to the standard similarity. For this, we generalize the well-known cosine similarity measure in VSM by introducing what we call "soft cosine measure". We propose various formulas for exact or approximate calculation of the soft cosine measure. For example, in one of them we consider for VSM a new feature space consisting of pairs of the original features weighted by their similarity. Again, for features that bear no similarity to each other, our formulas reduce to the standard cosine measure. Our experiments show that our soft cosine measure provides better performance in our case study: entrance exams question answering task at CLEF. In these experiments, we use syntactic n-grams as features and Levenshtein distance as the similarity between n-grams, measured either in characters or in elements of n-grams.},
author = {Sidorov, Grigori and Gelbukh, Alexander and G{\'{o}}mez-Adorno, Helena and Pinto, David},
doi = {10.13053/CyS-18-3-2043},
file = {:Users/anne/Downloads/v18n3a7.pdf:pdf},
issn = {20079737},
journal = {Computacion y Sistemas},
keywords = {Levenshtein distance,N-grams,Similarity between features,Soft cosine measure,Soft similarity,Syntactic n-grams,Vector space model},
number = {3},
pages = {491--504},
title = {{Soft similarity and soft cosine measure: Similarity of features in vector space model}},
volume = {18},
year = {2014}
}


@article{Hager2020,
abstract = {Does public opinion affect political speech? Of particular interest is whether public opinion affects (i) what topics politicians address and (ii) what positions they endorse. We present evidence from Germany where the government was recently forced to declassify its public opinion research, allowing us to link the content of the research to subsequent speeches. Our causal identification strategy exploits the exogenous timing of the research's dissemination to cabinet members within a window of a few days. We find that exposure to public opinion research leads politicians to markedly change their speech. First, we show that linguistic similarity between political speech and public opinion research increases significantly after reports are passed on to the cabinet, suggesting that politicians change the topics they address. Second, we demonstrate that exposure to public opinion research alters politicians' substantive positions in the direction of majority opinion.},
author = {Hager, Anselm and Hilbig, Hanno},
doi = {10.1111/ajps.12516},
file = {:Users/anne/Downloads/45295357.pdf:pdf},
issn = {15405907},
journal = {American Journal of Political Science},
number = {4},
pages = {921--937},
title = {{Does public opinion affect political speech?}},
volume = {64},
year = {2020}
}

@article{Maier2018,
abstract = {Latent Dirichlet allocation (LDA) topic models are increasingly being used in communication research. Yet, questions regarding reliability and validity of the approach have received little attention thus far. In applying LDA to textual data, researchers need to tackle at least four major challenges that affect these criteria: (a) appropriate pre-processing of the text collection; (b) adequate selection of model parameters, including the number of topics to be generated; (c) evaluation of the model's reliability; and (d) the process of validly interpreting the resulting topics. We review the research literature dealing with these questions and propose a methodology that approaches these challenges. Our overall goal is to make LDA topic modeling more accessible to communication researchers and to ensure compliance with disciplinary standards. Consequently, we develop a brief hands-on user guide for applying LDA topic modeling. We demonstrate the value of our approach with empirical data from an ongoing research project.},
author = {Maier, Daniel and Waldherr, A. and Miltner, P. and Wiedemann, G. and Niekler, A. and Keinert, A. and Pfetsch, B. and Heyer, G. and Reber, U. and H{\"{a}}ussler, T. and Schmid-Petri, H. and Adam, S.},
doi = {10.1080/19312458.2018.1430754},
file = {:Users/anne/Downloads/Applying LDA Topic Modeling in Communication Research Toward a Valid and Reliable Methodology.pdf:pdf},
issn = {19312466},
journal = {Communication Methods and Measures},
number = {2-3},
pages = {93--118},
publisher = {Routledge},
title = {{Applying LDA Topic Modeling in Communication Research: Toward a Valid and Reliable Methodology}},
url = {https://doi.org/10.1080/19312458.2018.1430754},
volume = {12},
year = {2018}
}

@INPROCEEDINGS{Rehurek10softwareframework,
    author = {Radim Rehurek and Petr Sojka},
    title = {Software Framework for Topic Modelling with Large Corpora},
    booktitle = {IN PROCEEDINGS OF THE LREC 2010 WORKSHOP ON NEW CHALLENGES FOR NLP FRAMEWORKS},
    year = {2010},
    pages = {45--50},
    publisher = {}
}
